{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "# The `stop` is defined as earlier in this chapter\n",
    "# Added it here for convenience, so that this section\n",
    "# can be run as standalone without executing prior code\n",
    "# in the directory\n",
    "stop = stopwords.words('german')\n",
    "\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) +\\\n",
    "        ' '.join(emoticons).replace('-', '')\n",
    "    tokenized = [w for w in text.split() if w not in stop]\n",
    "    #tokenized = [w for w in text.split()]\n",
    "    return tokenized\n",
    "\n",
    "\n",
    "def stream_docs(path):\n",
    "    with open(path, 'r', encoding='utf-8') as csv:\n",
    "        next(csv)  # skip header\n",
    "        for line in csv:\n",
    "            text, label = line[:-3], int(line[-2])\n",
    "            yield text, label            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SnowballStemmer (Porter vs. German):\n",
      "Sentence # 0 :\" @Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverständlich. Dass das BVerfG Sachleistungen nicht ausschließt kritisieren wir.,0\n",
      " \"\n",
      " =>  martin28a : martin28a | martin28a\n",
      " =>  ja : ja | ja\n",
      " =>  recht : recht | recht\n",
      " =>  tweet : tweet | tweet\n",
      " =>  missverständlich : missverständlich | missverstand\n",
      " =>  bverfg : bverfg | bverfg\n",
      " =>  sachleistungen : sachleistungen | sachleist\n",
      " =>  ausschließt : ausschließt | ausschliesst\n",
      " =>  kritisieren : kritisieren | kritisi\n",
      " =>  0 : 0 | 0\n",
      "\n",
      "SnowballStemmer (Porter vs. German):\n",
      "Sentence # 500 :\" \"@MartinSchulz Ihr hetzt permanent gegen Trump. Und diese \"\"Demokratiebgemeinschaft Europa\"\" ist auf Sand gebaut und aus dem Geld des von euch ausgebeuteten kleinen Mannes. Dann lieber \"\"Amerika First\"\"  - das ist echt das ist ehrlich da kann sich der Ami (egal welche Farbe) mit identifizieren\",0\n",
      " \"\n",
      " =>  martinschulz : martinschulz | martinschulz\n",
      " =>  hetzt : hetzt | hetzt\n",
      " =>  permanent : perman | permanent\n",
      " =>  trump : trump | trump\n",
      " =>  demokratiebgemeinschaft : demokratiebgemeinschaft | demokratiebgemeinschaft\n",
      " =>  europa : europa | europa\n",
      " =>  sand : sand | sand\n",
      " =>  gebaut : gebaut | gebaut\n",
      " =>  geld : geld | geld\n",
      " =>  ausgebeuteten : ausgebeuteten | ausgebeutet\n",
      " =>  kleinen : kleinen | klein\n",
      " =>  mannes : mann | mann\n",
      " =>  lieber : lieber | lieb\n",
      " =>  amerika : amerika | amerika\n",
      " =>  first : first | first\n",
      " =>  echt : echt | echt\n",
      " =>  ehrlich : ehrlich | ehrlich\n",
      " =>  ami : ami | ami\n",
      " =>  egal : egal | egal\n",
      " =>  farbe : farb | farb\n",
      " =>  identifizieren : identifizieren | identifizi\n",
      " =>  0 : 0 | 0\n",
      "\n",
      "SnowballStemmer (Porter vs. German):\n",
      "Sentence # 1000 :\" @Pxg96fcb Trotzdem kann mans ändern jeder ist selbst der Widerstand,1\n",
      " \"\n",
      " =>  pxg96fcb : pxg96fcb | pxg96fcb\n",
      " =>  trotzdem : trotzdem | trotzd\n",
      " =>  mans : man | man\n",
      " =>  ändern : ändern | and\n",
      " =>  widerstand : widerstand | widerstand\n",
      " =>  1 : 1 | 1\n",
      "\n",
      "SnowballStemmer (Porter vs. German):\n",
      "Sentence # 1500 :\" @Phatentophon @OnkelJakob @maischberger @sebastiankurz lassen wir es. sie verstehen oder wollen es nicht verstehen. schade,0\n",
      " \"\n",
      " =>  phatentophon : phatentophon | phatentophon\n",
      " =>  onkeljakob : onkeljakob | onkeljakob\n",
      " =>  maischberger : maischberg | maischberg\n",
      " =>  sebastiankurz : sebastiankurz | sebastiankurz\n",
      " =>  lassen : lassen | lass\n",
      " =>  verstehen : verstehen | versteh\n",
      " =>  verstehen : verstehen | versteh\n",
      " =>  schade : schade | schad\n",
      " =>  0 : 0 | 0\n",
      "\n",
      "SnowballStemmer (Porter vs. German):\n",
      "Sentence # 2000 :\" @NiciD_95 @patricia_seelig @spdrlp @D_Stich ich war immer dafür das wie beim letzten mal die mitglieder entscheiden und nicht die funktionäre.,0\n",
      " \"\n",
      " =>  nicid_95 : nicid_95 | nicid_95\n",
      " =>  patricia_seelig : patricia_seelig | patricia_seel\n",
      " =>  spdrlp : spdrlp | spdrlp\n",
      " =>  d_stich : d_stich | d_stich\n",
      " =>  immer : immer | imm\n",
      " =>  dafür : dafür | dafur\n",
      " =>  beim : beim | beim\n",
      " =>  letzten : letzten | letzt\n",
      " =>  mal : mal | mal\n",
      " =>  mitglieder : mitglied | mitglied\n",
      " =>  entscheiden : entscheiden | entscheid\n",
      " =>  funktionäre : funktionär | funktionar\n",
      " =>  0 : 0 | 0\n",
      "\n",
      "SnowballStemmer (Porter vs. German):\n",
      "Sentence # 2500 :\" Und: Nur mit transparenteren Steuerregeln in EU können wir auch weltweit glaubwürdig für mehr Steuergerechtigkeit eintreten. #paradisepapers,0\n",
      " \"\n",
      " =>  transparenteren : transparenteren | transparent\n",
      " =>  steuerregeln : steuerregeln | steuerregeln\n",
      " =>  eu : eu | eu\n",
      " =>  weltweit : weltweit | weltweit\n",
      " =>  glaubwürdig : glaubwürdig | glaubwurd\n",
      " =>  mehr : mehr | mehr\n",
      " =>  steuergerechtigkeit : steuergerechtigkeit | steuergerecht\n",
      " =>  eintreten : eintreten | eintret\n",
      " =>  paradisepapers : paradisepap | paradisepap\n",
      " =>  0 : 0 | 0\n",
      "\n",
      "SnowballStemmer (Porter vs. German):\n",
      "Sentence # 3000 :\" @AntaroTV Ja weil Merkel dann abdeschossen wäre wenn so ein Unding zustande käme wäre wohl Voraussetzung für Koa. .,0\n",
      " \"\n",
      " =>  antarotv : antarotv | antarotv\n",
      " =>  ja : ja | ja\n",
      " =>  merkel : merkel | merkel\n",
      " =>  abdeschossen : abdeschossen | abdeschoss\n",
      " =>  wäre : wäre | war\n",
      " =>  unding : und | unding\n",
      " =>  zustande : zustand | zustand\n",
      " =>  käme : käme | kam\n",
      " =>  wäre : wäre | war\n",
      " =>  wohl : wohl | wohl\n",
      " =>  voraussetzung : voraussetzung | voraussetz\n",
      " =>  koa : koa | koa\n",
      " =>  0 : 0 | 0\n",
      "\n",
      "SnowballStemmer (Porter vs. German):\n",
      "Sentence # 3500 :\" Ihr afghanischen Jugendlichen! Haut doch nicht ab Ihr Feiglinge und |LBR| kümmert Euch um Eure Angelegenheiten in Eurer Heimat.,1\n",
      " \"\n",
      " =>  afghanischen : afghanischen | afghan\n",
      " =>  jugendlichen : jugendlichen | jugend\n",
      " =>  haut : haut | haut\n",
      " =>  ab : ab | ab\n",
      " =>  feiglinge : feigling | feigling\n",
      " =>  lbr : lbr | lbr\n",
      " =>  kümmert : kümmert | kummert\n",
      " =>  angelegenheiten : angelegenheiten | angeleg\n",
      " =>  heimat : heimat | heimat\n",
      " =>  1 : 1 | 1\n",
      "\n",
      "SnowballStemmer (Porter vs. German):\n",
      "Sentence # 4000 :\" @Platiniumray Sicher doch und es würde besser gehen wenn 100TSD Mecklenburger Kühe das politische Berlin zuscheißen würden ??,1\n",
      " \"\n",
      " =>  platiniumray : platiniumray | platiniumray\n",
      " =>  sicher : sicher | sich\n",
      " =>  besser : besser | bess\n",
      " =>  gehen : gehen | geh\n",
      " =>  100tsd : 100tsd | 100tsd\n",
      " =>  mecklenburger : mecklenburg | mecklenburg\n",
      " =>  kühe : kühe | kuh\n",
      " =>  politische : politisch | polit\n",
      " =>  berlin : berlin | berlin\n",
      " =>  zuscheißen : zuscheißen | zuscheiss\n",
      " =>  1 : 1 | 1\n",
      "\n",
      "SnowballStemmer (Porter vs. German):\n",
      "Sentence # 4500 :\" Identitär sein heißt unsere Geschichte in ihrer Gänze annehmen sich für die Fehler zu schämen und stolz auf ihre Erfolge zu sein - aus Fehlern zu lernen und alte Größe neu anzustreben.,0\n",
      " \"\n",
      " =>  identitär : identitär | identitar\n",
      " =>  heißt : heißt | heisst\n",
      " =>  geschichte : geschicht | geschicht\n",
      " =>  gänze : gänze | ganz\n",
      " =>  annehmen : annehmen | annehm\n",
      " =>  fehler : fehler | fehl\n",
      " =>  schämen : schämen | scham\n",
      " =>  stolz : stolz | stolz\n",
      " =>  erfolge : erfolg | erfolg\n",
      " =>  fehlern : fehlern | fehl\n",
      " =>  lernen : lernen | lern\n",
      " =>  alte : alt | alt\n",
      " =>  größe : größe | gross\n",
      " =>  neu : neu | neu\n",
      " =>  anzustreben : anzustreben | anzustreb\n",
      " =>  0 : 0 | 0\n",
      "\n",
      "SnowballStemmer (Porter vs. German):\n",
      "Sentence # 5000 :\" Wie viele Schüler sind evangelisch? Und wie viele Schüler sind |LBR| ohne Glaubensbekenntnis? Dann erst werden Eure Zahlen vergleichbar.,0\n",
      " \"\n",
      " =>  viele : viel | viel\n",
      " =>  schüler : schüler | schul\n",
      " =>  evangelisch : evangelisch | evangel\n",
      " =>  viele : viel | viel\n",
      " =>  schüler : schüler | schul\n",
      " =>  lbr : lbr | lbr\n",
      " =>  glaubensbekenntnis : glaubensbekenntni | glaubensbekenntnis\n",
      " =>  erst : erst | erst\n",
      " =>  zahlen : zahlen | zahl\n",
      " =>  vergleichbar : vergleichbar | vergleichbar\n",
      " =>  0 : 0 | 0\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer \n",
    "\n",
    "def stem_sentence(index, sentence):\n",
    "    words = tokenizer(sentence)\n",
    "\n",
    "    # print(\" \".join(SnowballStemmer.languages))\n",
    "\n",
    "    print(\"\\nSnowballStemmer (Porter vs. German):\")\n",
    "    sPorter = SnowballStemmer(\"porter\")\n",
    "    sGerman = SnowballStemmer(\"german\")\n",
    "    \n",
    "    print(\"Sentence #\", index, \":\\\"\", sentence, \"\\\"\")\n",
    "    for w in words: \n",
    "        print(\" => \", w, \":\", sPorter.stem(w), \"|\", sGerman.stem(w))\n",
    "    \n",
    "def stem_file(path, sample):\n",
    "    with open(path, 'r', encoding='utf-8') as csv:\n",
    "        next(csv)\n",
    "        i = 0\n",
    "        for line in csv:\n",
    "            if i % sample == 0:\n",
    "                stem_sentence(index=i, sentence=line)\n",
    "            i += 1\n",
    "            \n",
    "stem_file(path='german_emotions.csv', sample=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "german_emotions.csv => german_emotions_shuffled.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def shuffle(path, rename):\n",
    "    df = pd.read_csv(path, header=0)\n",
    "    frame = df.reindex(np.random.permutation(df.index))\n",
    "    if rename == 1:\n",
    "        name = path[:path.rindex('.')]\n",
    "        extension = path[path.rindex('.'):]\n",
    "        newPath = name + \"_shuffled\" + extension\n",
    "        print(path, '=>', newPath)\n",
    "        frame.to_csv(newPath, sep=';', index=False, header=False)\n",
    "    else:\n",
    "        frame.to_csv(path, sep=';', index=False, header=False)\n",
    "        \n",
    "shuffle(path='german_emotions.csv', rename=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/martinkade/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('@Martin28a Sie haben ja auch Recht. Unser Tweet war etwas missverständlich. Dass das BVerfG Sachleistungen nicht ausschließt kritisieren wir.',\n",
       " 0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(stream_docs(path='german_emotions.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minibatch(doc_stream, size):\n",
    "    docs, y = [], []\n",
    "    try:\n",
    "        for _ in range(size):\n",
    "            text, label = next(doc_stream)\n",
    "            docs.append(text)\n",
    "            y.append(label)\n",
    "    except StopIteration:\n",
    "        return None, None\n",
    "    return docs, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "vect = HashingVectorizer(decode_error='ignore', \n",
    "                         n_features=2**21,\n",
    "                         preprocessor=None, \n",
    "                         tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distutils.version import LooseVersion as Version\n",
    "from sklearn import __version__ as sklearn_version\n",
    "\n",
    "if Version(sklearn_version) < '0.18':\n",
    "    clf = SGDClassifier(loss='log', random_state=1, n_iter=1)\n",
    "else:\n",
    "    clf = SGDClassifier(loss='log', random_state=1, max_iter=1)\n",
    "\n",
    "doc_stream = stream_docs(path='german_emotions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OTHER\n",
    "#PROFANITY\n",
    "#ABUSE\n",
    "#INSULT\n",
    "#OFFENSE\n",
    "\n",
    "#Only needed for progressbar\n",
    "#import pyprind\n",
    "#pbar = pyprind.ProgBar(45)\n",
    "\n",
    "classes = np.array([0, 1])\n",
    "for _ in range(45):\n",
    "    X_train, y_train = get_minibatch(doc_stream, size=100)\n",
    "    if not X_train:\n",
    "        break\n",
    "    X_train = vect.transform(X_train)\n",
    "    clf.partial_fit(X_train, y_train, classes=classes)\n",
    "    #pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.752\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = get_minibatch(doc_stream, size=500)\n",
    "X_test = vect.transform(X_test)\n",
    "print('Accuracy: %.3f' % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = clf.partial_fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.714\n"
     ]
    }
   ],
   "source": [
    "doc_stream = stream_docs(path='german_validation.csv')\n",
    "\n",
    "X_val, y_val = get_minibatch(doc_stream, size=7)\n",
    "X_val = vect.transform(X_val)\n",
    "print('Accuracy: %.3f' % clf.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(X_val)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
